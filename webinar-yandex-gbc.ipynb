{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "tll9ofc41bc7f0uchagxnm"
   },
   "source": [
    "# Задача распознавания говорящего по голосу"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "ouwakt5asjvaowvc6qahe"
   },
   "source": [
    "## I. Постановка задачи"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "h33nxhqk056r5agev40cz9"
   },
   "source": [
    "На основании имеющихся данных мы хотим научиться определять говорящего. **Data-set** представляет собой набор, состоящий из\n",
    "1. Trainig corpus. Голосовые высказывания спикеров (несколько записей по каждому спикеру).\n",
    "2. Test corpus. Другие записи тех же спикеров.\n",
    "\n",
    "Все аудиофайлы имеют длительность 10 sec и сэмплируются на частоте 16000 Hz."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "3qgydy9hkb5gbr1cn7b35g"
   },
   "source": [
    "## II. Введение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "x86k14nyl4sqty8uqvqdof"
   },
   "source": [
    "Речевой сигнал представляет собой последовательность чисел, которые определяют амплитуду говорящего. Вся концепция распознования речи базируется на трёх основных принципах/инструментах:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "4176ljwxii4hirtfcpy99e"
   },
   "source": [
    "### 1. Framing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "l9jaf7129g79lfoywc22cq"
   },
   "source": [
    "Поскольку речь не является стационарным сигналом (стационарностью называется свойство процесса сохранять свои характеристики с течением времени), её частотное содержание постоянно изменяется во времени. Чтобы выполнить хотя бы какой-нибудь анализ сигнала на коротких временных интервалах (*Short Term Fourier Transformation*), нам надо иметь возможность рассмотреть сигнал как стационарный. Чтобы достичь этой стационарности, речевой сигнал делится на ***фреймы*** длинной 20-30 ms. На такой длине можно сделать предположение о том, что форма волны не изменяется или изменяется совсем незначительно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "qp8rqs3yauf5uxmkli764"
   },
   "source": [
    "![frame-segmentation](presentation/Segmentation-of-speech-signals-frame-by-frame.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "vxf2fiflkuflvc13aj2ga"
   },
   "source": [
    "### 2. Windowing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "28sl781qjhzfwxd9xvjdih"
   },
   "source": [
    "Извлечение фреймов из речевого сигнала может привести к разрывам в целых точках из-за нецелого числа периодов в извлечённом сигнале, что в свою очередь может привести к ошибочному представлению частоты (говорят, что случается *спектральная утечка* ~ *spectral leakage*). Это можно предотвратить умножением фрейма на некоторую ***оконную функцию***. Амплитуда оконной функции падает до нуля на концах фрейма, что естественным образом минимизирует амплитуду разрыва."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "ehdx8pxhuy581lbvm2tqxg"
   },
   "source": [
    "На картинках ниже приведена иллюстррация фрейма до и после умножения на оконную функцию."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "24o5kqlbnrpg42gxlhevrg7"
   },
   "source": [
    "![non-integer](presentation/noninteger1.png) ![windowing](presentation/window2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "bocap5skzajdbr5niyhxer"
   },
   "source": [
    "### 3. Overlapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "obodxfc65fzhsfzrbyq6"
   },
   "source": [
    "Из-за windowing'а возможна ситуация, когда в результате \"сужения\" мы теряем часть информации о сигнале на концах фрейма. Чтобы нивелировать этот возможный деффект необходимо сделать ***перекрытие*** фреймов. Суть его в следующем: пусть фрейм *s* имеет длину 20-30 ms, возьмём фрейм *s+1*, который также имеет длину 20-30 ms и \"наложим\" его частично на фрейм *i*, длина перекрытия обычно равна 10-15 ms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "7em8vm2qwkpi51tj08ehmh"
   },
   "source": [
    "Приведём поясняющую иллюстрацию."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "l6gvf11j5s8jxh2bp8beb"
   },
   "source": [
    "![overlapping](presentation/mfcc_audioframes.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "08oqlpppbhtw8s9s08t57m6"
   },
   "source": [
    "## III. Gaussian Mixture Model (GMM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "ey4mv4w0tcedw0eiugk1b"
   },
   "source": [
    "***Gaussian Mixture Model (GMM)*** – вероятностная модель кластеризации для представления присутствия под-популяции в охватывающей популяции. Идея обучения GMM – приблизить распределение вероятности класса линейной комбинацией $k$ гауссовых распределений, которые также называются компонентами GMM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "wyliqedwfsesesr84dpk"
   },
   "source": [
    "Вероятность точек данных (векторов признака) для модели задаётся следующим образом"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "nupxl42vkkep6ea72eso2i"
   },
   "source": [
    "$\\mathbf{P} (\\mathbf{x} \\vert \\lambda) = \\sum_{k = 1}^{K} \\omega_k f_{\\mathbf{X}_k}(\\mathbf{x})$, где"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "30v9zelnbql38624of9mz"
   },
   "source": [
    "$f_{\\mathbf{X}}(\\mathbf{x}) = \\frac{1}{(2\\pi )^{n/2} \\vert \\Sigma \\vert^{1/2}} e^{-\\frac{1}{2}(\\mathbf{x} - \\mathbf{\\mu})^{\\top} \\Sigma^{-1} (\\mathbf{x} - \\mathbf{\\mu})},\\; \\mathbf{x} \\in \\mathbb{R}^n$, \n",
    "\n",
    "где $\\vert \\Sigma\\vert$ — определитель матрицы $\\Sigma$, а $\\Sigma^{-1}$ — матрица, обратная к $\\Sigma$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "xkudscbocf44a4q5fubmr"
   },
   "source": [
    "Training data $X_i$ класса $\\lambda$ используется для оценки значений всех параметров."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "lwcxro34pr4vekucnlf7g"
   },
   "source": [
    "Вначале определяется $k$ классв в данных $K$-средним алгоритмом и с весами $\\omega = 1/k$ для каждого кластера. Затем $k$ гауссовых распределений фитят $k$ кластеров, все параметры при этом обновляются итеративно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "onc2mbh3vuy9wadibl5r"
   },
   "source": [
    "## IV. Демонстрация решения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "435wj1zq66s4umyt6o5se3"
   },
   "source": [
    "### Установка и импорт необходимых пакетов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "tz8jup8rqxf00gno8y6tg"
   },
   "outputs": [],
   "source": [
    "%pip install numba==0.48.0\n",
    "%pip install librosa\n",
    "%pip install cffi==1.14.0\n",
    "%pip show numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "cellId": "hxe1msiec5fztvibbp8y8f"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "\n",
    "import librosa\n",
    "from librosa import display\n",
    "from IPython.display import Audio \n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "ajci27r87hczre6vmwhoim"
   },
   "source": [
    "### Получение данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "376zvspk3tqx3z6ne5pc"
   },
   "source": [
    "Snippets -> Extract Zip file.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "58sjsz6c7u8wpm7arf1mia"
   },
   "source": [
    "### Генерация аудио-признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "lpwude9n8od1c61dun5cu9"
   },
   "source": [
    "Создадим функцию, которая будет извлекать аудио-признаки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "cellId": "ay7n7dmrl1tbi4y68osks4"
   },
   "outputs": [],
   "source": [
    "def audio_features_extraction(sample, sample_rate, n_fft):\n",
    "    \n",
    "    \"\"\" \n",
    "        sample - audio time series\n",
    "        sample_rate - sampling rate of sample\n",
    "        n_fft = frame size\n",
    "    \"\"\"\n",
    "    \n",
    "    # librosa.feature.mfcc - вычилсяет коэффициенты MFCCs.\n",
    "    # MFCCs трансформируют значение сигнала в кепстр – один из видов гомоморфной обработки сигналов, \n",
    "    # функция обратного преобразования Фурье от логарифма спектра мощности сигнала. \n",
    "    # Основная задача: охарактеризовать фильтр и отделить исходную часть\n",
    "    # (на примере с голосом человека – охарактеризовать вокальный тракт).\n",
    "    mfcc = librosa.feature.mfcc(y=sample, \n",
    "                                n_fft=n_fft, # размер фрейма\n",
    "                                window='hann',  # оконная функция (windowing)\n",
    "                                hop_length=int(n_fft*0.5), # размер перекрытия фреймов (overlapping)\n",
    "                                sr=sample_rate, \n",
    "                                n_mfcc=20)\n",
    "    features = np.mean(mfcc, axis=1)\n",
    "    \n",
    "    # librosa.feature.zero_crossing находит нулевые переходы для сигнала.\n",
    "    zero_crossings = sum(librosa.zero_crossings(sample, pad=False))\n",
    "    features = np.append(zero_crossings, features)\n",
    "    \n",
    "    # librosa.feature.spectral_centroid вычисляет спектральный центроид.\n",
    "    # Каждый фрейм амплитудной спектрограммы нормализуется и обрабатывается как распределение по частотным элементам,\n",
    "    # из которого извлекается среднее значение (центроид) для каждого фрейма.\n",
    "    spec_cent = librosa.feature.spectral_centroid(y=sample,n_fft=n_fft, hop_length=int(n_fft*0.5), window='hann', sr=sample_rate).mean()\n",
    "    features = np.append(spec_cent, features)\n",
    "    \n",
    "    # librosa.feature.spectral_flatness вычисляет cпектральную плоскостность.\n",
    "    # Спектральная плоскостность - количественная мера того, насколько звук похож на шум, а не на тон.\n",
    "    spec_flat = librosa.feature.spectral_flatness(y=sample,n_fft=n_fft, hop_length=int(n_fft*0.5), window='hann').mean()\n",
    "    features = np.append(spec_flat, features)\n",
    "    \n",
    "    # librosa.feature.spectral_bandwith вычисляет спектральную полосу пропускания p-ого порядка.\n",
    "    spec_bw = librosa.feature.spectral_bandwidth(y=sample,n_fft=n_fft, hop_length=int(n_fft*0.5), window='hann', sr=sample_rate).mean()\n",
    "    features = np.append(spec_bw, features)\n",
    "    \n",
    "    # librosa.feature.spectral_rolloff вычисляет roll-off частоту для каждого фрейма.\n",
    "    # Roll-off частота определяется как центральная частота для интервала спектрограммы.\n",
    "    rolloff = librosa.feature.spectral_rolloff(y=sample, n_fft=n_fft, hop_length=int(n_fft*0.5), window='hann', sr=sample_rate).mean()\n",
    "    features = np.append(rolloff, features)\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "u4awkxs4b43ixoavmci03"
   },
   "source": [
    "Читаем последовательно аудио-файлы и извлекаем аудио-признаки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "cellId": "yoicsxqstrd9xvvpxg7ajk"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Features extractions : 170it [01:14,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time:  75.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "/py-env/platform-env/lib/python3.7/site-packages/ml_platform/user_messages.py:13: UserWarning: \n",
      "\n",
      "The following variables cannot be serialized: features\n",
      "\n",
      "\n",
      "\n",
      "Please note that these variables can be lost in the next working session\n",
      "\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "source   = \"./webinar0813-yandex-gbc/data/development_set/\"  \n",
    "dest = \"./webinar0813-yandex-gbc/speaker-models/\"\n",
    "train_file = \"./webinar0813-yandex-gbc/data/development_set_enroll.txt\"\n",
    "file_paths = open(train_file, 'r')\n",
    " \n",
    "n_fft = 1024\n",
    "\n",
    "# Подготова датасетов для обучения моделей.\n",
    "features = pd.DataFrame()\n",
    "speakers = pd.DataFrame()\n",
    "\n",
    "# Последовательное чтение аудио-файлов из тренировочного семпла.\n",
    "for path in tqdm(file_paths, desc='Features extractions '):\n",
    "    path = path.replace(\"\\\\\",\"/\").strip()\n",
    "    speaker = path.split(\"-\",1)[0]\n",
    "\n",
    "    # librosa.load - загрузка аудио-файла.\n",
    "    sample, sample_rate = librosa.load(source+path)\n",
    "    \n",
    "    # Извлечение аудио-признаков.\n",
    "    features = features.append(pd.Series(audio_features_extraction(sample, sample_rate, n_fft)), ignore_index=True) \n",
    "    speakers = speakers.append({'speaker' : speaker}, ignore_index=True)\n",
    " \n",
    "print('Execution time: ', round((time.time() - start),2))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "tgq0it0wvjc18c8hqbwwwa"
   },
   "source": [
    "Нормируем признаки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "cellId": "s9yseie4829a8fnuy3fnf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/py-env/platform-env/lib/python3.7/site-packages/ml_platform/user_messages.py:13: UserWarning: \n",
      "\n",
      "The following variables cannot be serialized: features_scaled, features\n",
      "\n",
      "\n",
      "\n",
      "Please note that these variables can be lost in the next working session\n",
      "\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(features)\n",
    "features_scaled = pd.DataFrame(scaler.transform(features))\n",
    "pickle.dump(scaler, open('scaler','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "5sgff9ktpfw11k3nx5s2l"
   },
   "source": [
    "### Обучение моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "ip5mke42jaz2vtjtvpbs"
   },
   "source": [
    "Обучаем модели и сохраняем в директорию `speaker-models/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "cellId": "scidkmetempbwvwfhxfr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time:  0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/py-env/platform-env/lib/python3.7/site-packages/ml_platform/user_messages.py:13: UserWarning: \n",
      "\n",
      "The following variables cannot be serialized: features_scaled, features_smpl\n",
      "\n",
      "\n",
      "\n",
      "Please note that these variables can be lost in the next working session\n",
      "\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "features_smpl = pd.DataFrame()\n",
    "count = 1\n",
    "\n",
    "for i in range(speakers.shape[0]):\n",
    "    speaker = speakers.iloc[i:i+1].values[0]\n",
    "    if count == 1:\n",
    "        speaker_prev = speaker     \n",
    "    else :\n",
    "        # Обучение модели GaussianMixture для каждого спикера\n",
    "        if (speaker_prev != speaker) | (i == len(speakers)-1) :\n",
    "            gmm = GaussianMixture(n_components = min(16, features_smpl.shape[0]), \n",
    "                                  max_iter = 200, covariance_type='diag', n_init = 3)\n",
    "            gmm.fit(features_smpl)\n",
    "            \n",
    "            # Сохранение полученной модели в pickle\n",
    "            pickle.dump(gmm, open((dest+speaker_prev)[0],'wb'))\n",
    "            features_smpl = pd.DataFrame()\n",
    "            count = 0\n",
    "            speaker_prev = speaker\n",
    "            \n",
    "    # Сбор данных по одному спикеру.\n",
    "    features_smpl  = features_smpl.append(features_scaled.iloc[i:i+1], ignore_index=True)\n",
    "    count = count+1\n",
    "\n",
    "print('Execution time: ', round((time.time() - start),2)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "pdej0sspb28cctnvi2nmcv"
   },
   "source": [
    "### Тестирование на тестовом семпле"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "cellId": "fj8md7md185qnnvgxe5pqo"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Score test sample : 170it [01:14,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time:  74.99\n",
      "\n",
      "Точность угадывания, %:  98.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "source   = \"./webinar0813-yandex-gbc/data/development_set/\"  \n",
    "dest = \"./webinar0813-yandex-gbc/speaker-models/\"\n",
    "test_file = \"./webinar0813-yandex-gbc/data/development_set_test.txt\"\n",
    "file_paths = open(test_file,'r')\n",
    " \n",
    "n_fft = 1024\n",
    "\n",
    "features = pd.DataFrame()\n",
    "result = pd.DataFrame()\n",
    "\n",
    "gmm_files = [os.path.join(dest,fname) for fname in os.listdir(dest)]\n",
    "gmm_files = [fname for fname in gmm_files if not '.ipynb' in fname]\n",
    "models    = [pickle.load(open(fname,'rb')) for fname in gmm_files ]\n",
    "scaler    = pickle.load(open('scaler','rb'))\n",
    "\n",
    "# Последовательное чтение аудио-файлов из тестового семпла.\n",
    "for path in tqdm(file_paths, desc='Score test sample '):\n",
    "    \n",
    "    features = pd.DataFrame()\n",
    "    \n",
    "    path = path.replace(\"\\\\\",\"/\").strip()\n",
    "    speaker = path.split(\"-\",1)[0]\n",
    "    \n",
    "    # librosa.load - загрузка аудио-файла.\n",
    "    sample, sample_rate = librosa.load(source+path)\n",
    "    \n",
    "    # Извлечение аудио-признаков.\n",
    "    features = features.append(pd.Series(audio_features_extraction(sample, sample_rate, n_fft)), ignore_index=True) \n",
    "\n",
    "    # Нормирование аудио-признаков.\n",
    "    features = scaler.transform(features)\n",
    "    \n",
    "    # Скоринг каждой моделью\n",
    "    log_likelihood = np.zeros(len(models)) \n",
    "    for i in range(len(models)):\n",
    "        gmm = models[i] \n",
    "        scores = np.array(gmm.score(features))\n",
    "        log_likelihood[i] = scores.sum()\n",
    "        \n",
    "    # Выбор спикера по наибольшему скору\n",
    "    winner = np.argmax(log_likelihood)\n",
    "    result = result.append({'speaker' : speaker,\n",
    "                           'winner' : gmm_files[winner].split(\"/\",3)[-1]}, ignore_index=True)\n",
    "    \n",
    "print('Execution time: ', round((time.time() - start),2))   \n",
    "print('Точность угадывания, %: ', round(100*result[result['speaker']==result['winner']].shape[0]/result.shape[0],2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "ca0ly2y2ifam1i81gizrp"
   },
   "outputs": [],
   "source": [
    "result.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Yandex DataSphere Kernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "notebookId": "fd81de9f-569c-4ab6-bbf5-292d5e02d661"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
